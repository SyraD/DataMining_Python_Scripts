{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Framework for Datamining Twitter Using an Object Oriented Style Scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the app_key, app_secret, oauth_token, and oauth_token_secret from your twitter application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createKeys():\n",
    "    app_key='XX'      \n",
    "    app_secret='XX'\n",
    "    oauth_token='XX'\n",
    "    oauth_token_secret='XX'\n",
    "    return app_key,app_secret,oauth_token, oauth_token_secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Base code by Dr. Gregory Saxton. Twitter: @gregorysaxton, website: social-metrics.org\n",
    "#import sys\n",
    "#sys.path.insert(0, './Imports') #adds Imports folder to path\n",
    "#from Auth import * #import all variables stored in Imports/Keys.py \n",
    "\n",
    "def get_data_search(twitter_auth, search_keyword, tweets_toGather, max_id=None):\n",
    "    try:\n",
    "        '''\n",
    "        NOTES FROM https://dev.twitter.com/docs/api/1.1/get/search/tweets \n",
    "        'count' = 'The number of tweets to return per page, up to a maximum of 100 per request. Defaults to 15.' \n",
    "         'result_type' options:\n",
    "              * mixed: Include both popular and real time results in the response.\n",
    "              * recent: return only the most recent results in the response\n",
    "              * popular: return only the most popular results in the response.\n",
    "        https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "        '''\n",
    "        twitter_dictResponse = twitter_auth.search(q=search_keyword, count = tweets_toGather, result_type = 'recent') \n",
    "        \n",
    "    except Exception, e:\n",
    "        print \"Error reading id %s, exception: %s\" % (search_keyword, e)\n",
    "        return None\n",
    "        \n",
    "    print \"GRABBED: \", len(twitter_dictResponse['statuses']), \"statuses****\"\n",
    "    print \"max_id VALUE USED FOR THIS GRAB-->\", max_id\n",
    "    print \"returned twitter response as \", type(twitter_dictResponse),\" for keyword: \", search_keyword\n",
    "    return search_keyword, twitter_dictResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Tweet class\n",
    "class Tweet:\n",
    "   'Common base class for all Tweets'\n",
    "\n",
    "   def __init__(self, search_term, tweet_json):\n",
    "      self.searchTerm = search_term\n",
    "      self.tweetID = tweet_json[u'id']\n",
    "      self.text = tweet_json[u'text'].encode('ascii', 'ignore')\n",
    "      self.retweet_count = tweet_json[u'retweet_count']\n",
    "      self.fav_count = tweet_json[u'favorite_count']\n",
    "      self.entities_list = tweet_json[u'entities']\n",
    "      self.url_list = tweet_json[u'entities'][u'urls']\n",
    "      self. hashtag_list =  tweet_json[u'entities'][u'hashtags']\n",
    "      self.mentions_list = tweet_json[u'entities'][u'user_mentions']\n",
    "      self.coordinates = tweet_json[u'coordinates']\n",
    "        \n",
    "   def display_all(self):\n",
    "      print \"\\nsearched: \", self.searchTerm,\"\\nFound:\", self.text, '\\n     RT: ', self.retweet_count, 'Fav: ', self.fav_count \n",
    "\n",
    "   \n",
    "   def table_attributes(self):\n",
    "      return dict(searchTerm= str(self.searchTerm), tweetID = self.tweetID, text = self.text, \n",
    "                 retweet_count =self.retweet_count,fav_count = self.fav_count)\n",
    " \n",
    "    ## TODO - create url, entities, hashtags, mentions, and coordinate factories\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Helper Methods to Create Tweet_List with Tweet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TweetObj_from_StatusList(search_term, status_list):\n",
    "    ## create tweet object for each status and save to a list of tweets\n",
    "    print \"creating tweet objects from status list\"\n",
    "    wait_dots = '.'\n",
    "    print \"working\\n\", wait_dots\n",
    "    for entry in status_list:\n",
    "        wait_dots = wait_dots + wait_dots\n",
    "        print wait_dots\n",
    "        tweet_list.append(Tweet(search_term, entry))\n",
    "    return tweet_list\n",
    "#call from TweetObj_from_StatusList(keyword_output['statuses']) \n",
    "\n",
    "##for debugging\n",
    "#for tweet in tweet_list:\n",
    "#    tweet.display_all() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Method to Create SQL from Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#as transaction called tx, commits once all tweets inserted to tx\n",
    "def toSQL(tweet_list):\n",
    "    with dataset.connect('sqlite:///BasicTweet3.db') as tx:\n",
    "        try:\n",
    "            tx.begin()\n",
    "            for tweet in tweet_list:\n",
    "                tx['Tweet'].insert(tweet.table_attributes()) \n",
    "            tx.commit()\n",
    "            print \"Tweets in your sqlite database\"\n",
    "        except Exception, e:\n",
    "            print \"Error in uploading to sq, exception: %s\" % (e)\n",
    "            tx.rollback() #discard additions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dataset\n",
    "from twython import Twython\n",
    "\n",
    "tweet_list = []\n",
    "\n",
    "def  main():\n",
    "    app_key,app_secret,oauth_token, oauth_token_secret = createKeys()\n",
    "    twitter_auth = Twython(app_key=app_key, app_secret=app_secret, \n",
    "                       oauth_token=oauth_token, oauth_token_secret=oauth_token_secret)\n",
    "    print \"authenticating\"\n",
    "    keyword_output = get_data_search(twitter_auth, 'behaviordots', 4)\n",
    "    tweet_list = TweetObj_from_StatusList(keyword_output[0] , keyword_output[1]['statuses'])\n",
    "    print tweet_list\n",
    "    toSQL(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
